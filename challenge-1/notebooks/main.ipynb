{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":102672,"databundleVersionId":12375409,"sourceType":"competition"}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":1451.93327,"end_time":"2025-05-22T11:04:32.050242","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-05-22T10:40:20.116972","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#STEP 1: IMPORTS & SETUP\nimport os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import f1_score, classification_report\nfrom sklearn.model_selection import train_test_split\nfrom torchvision import datasets, transforms, models\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport torch.nn as nn\nimport torch.optim as optim\nfrom tqdm import tqdm\n","metadata":{"execution":{"iopub.status.busy":"2025-05-25T10:05:31.237509Z","iopub.execute_input":"2025-05-25T10:05:31.237717Z","iopub.status.idle":"2025-05-25T10:05:44.879069Z","shell.execute_reply.started":"2025-05-25T10:05:31.237695Z","shell.execute_reply":"2025-05-25T10:05:44.878437Z"},"papermill":{"duration":15.18075,"end_time":"2025-05-22T10:40:40.121513","exception":false,"start_time":"2025-05-22T10:40:24.940763","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Device setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using:\", device)\n\n# Paths\nBASE_PATH = '/kaggle/input/soil-classification/soil_classification-2025'\nTRAIN_DIR = os.path.join(BASE_PATH, 'train')\nTEST_DIR = os.path.join(BASE_PATH, 'test')\nLABELS_CSV = os.path.join(BASE_PATH, 'train_labels.csv')\nTEST_IDS_CSV = os.path.join(BASE_PATH, 'test_ids.csv')","metadata":{"execution":{"iopub.status.busy":"2025-05-25T10:05:44.880264Z","iopub.execute_input":"2025-05-25T10:05:44.880656Z","iopub.status.idle":"2025-05-25T10:05:44.978024Z","shell.execute_reply.started":"2025-05-25T10:05:44.880636Z","shell.execute_reply":"2025-05-25T10:05:44.977261Z"},"papermill":{"duration":0.014638,"end_time":"2025-05-22T10:40:40.138765","exception":false,"start_time":"2025-05-22T10:40:40.124127","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Using: cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"#  Load labels\ndf = pd.read_csv(LABELS_CSV)\ndf['image'] = df['image_id']\nlabel_mapping = {label: idx for idx, label in enumerate(df['soil_type'].unique())}\ninv_label_mapping = {v: k for k, v in label_mapping.items()}\ndf['label'] = df['soil_type'].map(label_mapping)\n\n#  Train/Val split\ntrain_df, val_df = train_test_split(df, test_size=0.15, stratify=df['label'], random_state=42)\n\n#  Transformations\nimage_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(15),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5]*3, [0.5]*3)\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5]*3, [0.5]*3)\n    ]),\n    'test': transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5]*3, [0.5]*3)\n    ])\n}","metadata":{"execution":{"iopub.status.busy":"2025-05-25T10:05:44.978879Z","iopub.execute_input":"2025-05-25T10:05:44.979132Z","iopub.status.idle":"2025-05-25T10:05:45.062369Z","shell.execute_reply.started":"2025-05-25T10:05:44.979104Z","shell.execute_reply":"2025-05-25T10:05:45.061806Z"},"papermill":{"duration":0.049388,"end_time":"2025-05-22T10:40:40.190742","exception":false,"start_time":"2025-05-22T10:40:40.141354","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"\n\n#  Dataset\nclass SoilDataset(Dataset):\n    def __init__(self, dataframe, img_dir, transform=None, is_test=False):\n        self.df = dataframe\n        self.img_dir = img_dir\n        self.transform = transform\n        self.is_test = is_test\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        image_id = self.df.iloc[idx]['image']\n        img_path = os.path.join(self.img_dir, image_id)\n        image = Image.open(img_path).convert('RGB')\n\n        if self.transform:\n            image = self.transform(image)\n\n        if self.is_test:\n            return image, image_id\n        else:\n            label = self.df.iloc[idx]['label']\n            return image, label\n\n#  Dataloaders\ntrain_dataset = SoilDataset(train_df, TRAIN_DIR, transform=image_transforms['train'])\nval_dataset = SoilDataset(val_df, TRAIN_DIR, transform=image_transforms['val'])\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\n#  Model\nmodel = models.resnet18(pretrained=True)\nmodel.fc = nn.Linear(model.fc.in_features, len(label_mapping))\nmodel = model.to(device)\n\n# Loss and Optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2025-05-25T10:05:45.063059Z","iopub.execute_input":"2025-05-25T10:05:45.063297Z","iopub.status.idle":"2025-05-25T10:05:45.958006Z","shell.execute_reply.started":"2025-05-25T10:05:45.063277Z","shell.execute_reply":"2025-05-25T10:05:45.957438Z"},"papermill":{"duration":0.632467,"end_time":"2025-05-22T10:40:40.826101","exception":false,"start_time":"2025-05-22T10:40:40.193634","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 167MB/s] \n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"#  Training loop\nEPOCHS = 10\nfor epoch in range(EPOCHS):\n    model.train()\n    train_loss = 0\n    for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{EPOCHS}'):\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    # Validation\n    model.eval()\n    val_preds, val_labels = [], []\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images = images.to(device)\n            outputs = model(images)\n            preds = outputs.argmax(1).cpu().numpy()\n            val_preds.extend(preds)\n            val_labels.extend(labels.numpy())\n\n    f1_scores = []\n    for i in range(len(label_mapping)):\n        f1 = f1_score(np.array(val_labels) == i, np.array(val_preds) == i)\n        f1_scores.append(f1)\n\n    print(f\"Epoch {epoch+1} - Train Loss: {train_loss:.4f}, Min F1: {min(f1_scores):.4f}, F1s: {f1_scores}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-05-25T10:05:45.960059Z","iopub.execute_input":"2025-05-25T10:05:45.960262Z","iopub.status.idle":"2025-05-25T10:08:18.962140Z","shell.execute_reply.started":"2025-05-25T10:05:45.960246Z","shell.execute_reply":"2025-05-25T10:08:18.961114Z"},"papermill":{"duration":1411.60423,"end_time":"2025-05-22T11:04:12.433298","exception":false,"start_time":"2025-05-22T10:40:40.829068","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"Epoch 1/10: 100%|██████████| 33/33 [00:20<00:00,  1.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 - Train Loss: 14.6895, Min F1: 0.8788, F1s: [0.9473684210526315, 0.8787878787878789, 1.0, 0.9428571428571428]\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10: 100%|██████████| 33/33 [00:12<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 - Train Loss: 3.8636, Min F1: 0.9123, F1s: [0.9693251533742331, 0.912280701754386, 1.0, 0.9705882352941176]\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10: 100%|██████████| 33/33 [00:12<00:00,  2.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 - Train Loss: 2.5771, Min F1: 0.9474, F1s: [0.9693251533742331, 0.9473684210526316, 1.0, 0.9705882352941176]\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10: 100%|██████████| 33/33 [00:12<00:00,  2.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 - Train Loss: 2.8722, Min F1: 0.9589, F1s: [0.974025974025974, 0.967741935483871, 0.9873417721518987, 0.958904109589041]\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/10: 100%|██████████| 33/33 [00:12<00:00,  2.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 - Train Loss: 2.4283, Min F1: 0.9831, F1s: [0.9937106918238994, 0.983050847457627, 1.0, 1.0]\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/10: 100%|██████████| 33/33 [00:12<00:00,  2.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 - Train Loss: 1.6562, Min F1: 0.9552, F1s: [0.9753086419753086, 0.983050847457627, 1.0, 0.955223880597015]\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/10: 100%|██████████| 33/33 [00:12<00:00,  2.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 - Train Loss: 1.0339, Min F1: 0.9831, F1s: [0.9937106918238994, 0.983050847457627, 1.0, 1.0]\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/10: 100%|██████████| 33/33 [00:12<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 - Train Loss: 1.4037, Min F1: 0.9677, F1s: [0.9746835443037974, 0.967741935483871, 0.9743589743589743, 1.0]\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/10: 100%|██████████| 33/33 [00:12<00:00,  2.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 - Train Loss: 1.0665, Min F1: 1.0000, F1s: [1.0, 1.0, 1.0, 1.0]\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/10: 100%|██████████| 33/33 [00:12<00:00,  2.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 - Train Loss: 1.3993, Min F1: 0.9855, F1s: [0.9937106918238994, 1.0, 1.0, 0.9855072463768115]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"\n#  Test prediction\ntest_ids = pd.read_csv(TEST_IDS_CSV)\ntest_ids['image'] = test_ids['image_id']\ntest_dataset = SoilDataset(test_ids, TEST_DIR, transform=image_transforms['test'], is_test=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\nmodel.eval()\ntest_preds = []\nimage_names = []\n\nwith torch.no_grad():\n    for images, image_ids in test_loader:\n        images = images.to(device)\n        outputs = model(images)\n        preds = outputs.argmax(1).cpu().numpy()\n        test_preds.extend(preds)\n        image_names.extend(image_ids)\n\n#  Map back to soil type\nfinal_labels = [inv_label_mapping[p] for p in test_preds]\nsubmission = pd.DataFrame({\n    'image_id': image_names,\n    'soil_type': final_labels\n})\n\nsubmission.to_csv('submission.csv', index=False)\nprint(\"submission.csv saved!\")\n","metadata":{"execution":{"iopub.status.busy":"2025-05-25T10:08:18.963004Z","iopub.execute_input":"2025-05-25T10:08:18.963229Z","iopub.status.idle":"2025-05-25T10:08:24.187507Z","shell.execute_reply.started":"2025-05-25T10:08:18.963209Z","shell.execute_reply":"2025-05-25T10:08:24.186910Z"},"papermill":{"duration":16.386667,"end_time":"2025-05-22T11:04:28.840077","exception":false,"start_time":"2025-05-22T11:04:12.453410","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"submission.csv saved!\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import pandas as pd\n\n# Load and display the submission file\nsubmission = pd.read_csv('submission.csv')\nsubmission.head(77)  # Show the first 10 predictions (you can change the number)\n","metadata":{"execution":{"iopub.status.busy":"2025-05-25T10:08:24.188285Z","iopub.execute_input":"2025-05-25T10:08:24.188596Z","iopub.status.idle":"2025-05-25T10:08:24.209407Z","shell.execute_reply.started":"2025-05-25T10:08:24.188548Z","shell.execute_reply":"2025-05-25T10:08:24.208706Z"},"papermill":{"duration":0.045591,"end_time":"2025-05-22T11:04:28.905931","exception":false,"start_time":"2025-05-22T11:04:28.860340","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"             image_id      soil_type\n0   img_cdf80d6f.jpeg  Alluvial soil\n1    img_c0142a80.jpg  Alluvial soil\n2    img_91168fb0.jpg  Alluvial soil\n3    img_9822190f.jpg  Alluvial soil\n4   img_e5fc436c.jpeg  Alluvial soil\n..                ...            ...\n72   img_64d9cdbe.jpg      Clay soil\n73   img_5e5ff453.jpg      Clay soil\n74   img_2c4f84e3.jpg      Clay soil\n75   img_0a40bbe2.jpg      Clay soil\n76   img_3bbdb754.jpg      Clay soil\n\n[77 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>soil_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>img_cdf80d6f.jpeg</td>\n      <td>Alluvial soil</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>img_c0142a80.jpg</td>\n      <td>Alluvial soil</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>img_91168fb0.jpg</td>\n      <td>Alluvial soil</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>img_9822190f.jpg</td>\n      <td>Alluvial soil</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>img_e5fc436c.jpeg</td>\n      <td>Alluvial soil</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>img_64d9cdbe.jpg</td>\n      <td>Clay soil</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>img_5e5ff453.jpg</td>\n      <td>Clay soil</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>img_2c4f84e3.jpg</td>\n      <td>Clay soil</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>img_0a40bbe2.jpg</td>\n      <td>Clay soil</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>img_3bbdb754.jpg</td>\n      <td>Clay soil</td>\n    </tr>\n  </tbody>\n</table>\n<p>77 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":7}]}
