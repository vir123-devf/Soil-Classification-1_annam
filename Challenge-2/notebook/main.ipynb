{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":102966,"databundleVersionId":12412856,"sourceType":"competition"}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# configuring the path of Kaggle.json file\n!pip install kaggle\n!mkdir -p ~/.kaggle\n!cp kaggle.json ~/.kaggle/\n!chmod 600 ~/.kaggle/kaggle.json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T17:22:08.128494Z","iopub.execute_input":"2025-05-25T17:22:08.129168Z","iopub.status.idle":"2025-05-25T17:22:11.530974Z","shell.execute_reply.started":"2025-05-25T17:22:08.129143Z","shell.execute_reply":"2025-05-25T17:22:11.530242Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.2)\nRequirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\nRequirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.4.26)\nRequirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.20.3)\nRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\nRequirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\nRequirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\nRequirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\nRequirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\nRequirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\ncp: cannot stat 'kaggle.json': No such file or directory\nchmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# 1. Imports and Setup\nimport os\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torchvision import models, transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom sklearn.svm import OneClassSVM\nfrom sklearn.preprocessing import StandardScaler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T17:22:11.532798Z","iopub.execute_input":"2025-05-25T17:22:11.533390Z","iopub.status.idle":"2025-05-25T17:22:11.538054Z","shell.execute_reply.started":"2025-05-25T17:22:11.533365Z","shell.execute_reply":"2025-05-25T17:22:11.537298Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# 2. Paths\ntrain_csv = '/kaggle/input/soil-classification-part-2/soil_competition-2025/train_labels.csv'\ntest_csv = '/kaggle/input/soil-classification-part-2/soil_competition-2025/test_ids.csv'\ntrain_dir = '/kaggle/input/soil-classification-part-2/soil_competition-2025/train'\ntest_dir = '/kaggle/input/soil-classification-part-2/soil_competition-2025/test'\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T17:22:11.538811Z","iopub.execute_input":"2025-05-25T17:22:11.539058Z","iopub.status.idle":"2025-05-25T17:22:11.549692Z","shell.execute_reply.started":"2025-05-25T17:22:11.539043Z","shell.execute_reply":"2025-05-25T17:22:11.549097Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# 3. Read CSVs\ntrain_df = pd.read_csv(train_csv)\ntest_df = pd.read_csv(test_csv)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T17:22:11.550610Z","iopub.execute_input":"2025-05-25T17:22:11.550882Z","iopub.status.idle":"2025-05-25T17:22:11.567569Z","shell.execute_reply.started":"2025-05-25T17:22:11.550859Z","shell.execute_reply":"2025-05-25T17:22:11.566772Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# 4.Preprocessing: resize and normalize for ResNet\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5]*3, [0.5]*3)  # Normalize to [-1, 1] range\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T17:22:11.569392Z","iopub.execute_input":"2025-05-25T17:22:11.569604Z","iopub.status.idle":"2025-05-25T17:22:11.574008Z","shell.execute_reply.started":"2025-05-25T17:22:11.569573Z","shell.execute_reply":"2025-05-25T17:22:11.573300Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"\n# 5. Custom Dataset\n\nclass SoilDataset(Dataset):\n    def __init__(self, dataframe, img_dir, transform):\n        self.df = dataframe\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        image_id = self.df.iloc[idx]['image_id']\n        image_path = os.path.join(self.img_dir, image_id)\n        image = Image.open(image_path).convert(\"RGB\")\n        image = self.transform(image)\n        return image, image_id\ntrain_dataset = SoilDataset(train_df, train_dir, transform)\ntest_dataset = SoilDataset(test_df, test_dir, transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T17:22:11.574616Z","iopub.execute_input":"2025-05-25T17:22:11.574770Z","iopub.status.idle":"2025-05-25T17:22:11.584375Z","shell.execute_reply.started":"2025-05-25T17:22:11.574758Z","shell.execute_reply":"2025-05-25T17:22:11.583737Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"#6. Load pretrained ResNet18 and remove the classifier head\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nresnet = models.resnet18(pretrained=True)\nresnet.fc = torch.nn.Identity()  # remove final layer\nresnet = resnet.to(device)\nresnet.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T17:22:11.584992Z","iopub.execute_input":"2025-05-25T17:22:11.585183Z","iopub.status.idle":"2025-05-25T17:22:11.827557Z","shell.execute_reply.started":"2025-05-25T17:22:11.585169Z","shell.execute_reply":"2025-05-25T17:22:11.826887Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Identity()\n)"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"# 7. Feature extraction function\ndef extract_features(dataloader):\n    features = []\n    ids = []\n    with torch.no_grad():\n        for images, image_ids in tqdm(dataloader):\n            images = images.to(device)\n            feats = resnet(images).cpu().numpy()\n            features.append(feats)\n            ids.extend(image_ids)\n    return np.vstack(features), ids","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T17:22:11.828238Z","iopub.execute_input":"2025-05-25T17:22:11.829111Z","iopub.status.idle":"2025-05-25T17:22:11.833477Z","shell.execute_reply.started":"2025-05-25T17:22:11.829085Z","shell.execute_reply":"2025-05-25T17:22:11.832757Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# 8. Extract features for training and testing\ntrain_features, _ = extract_features(train_loader)\ntest_features, test_ids = extract_features(test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T17:22:11.834220Z","iopub.execute_input":"2025-05-25T17:22:11.834559Z","iopub.status.idle":"2025-05-25T17:22:27.090246Z","shell.execute_reply.started":"2025-05-25T17:22:11.834543Z","shell.execute_reply":"2025-05-25T17:22:27.089349Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 39/39 [00:11<00:00,  3.46it/s]\n100%|██████████| 31/31 [00:03<00:00,  7.85it/s]\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# 9. Normalize features before feeding to SVM\nscaler = StandardScaler()\ntrain_features = scaler.fit_transform(train_features)\ntest_features = scaler.transform(test_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T17:22:27.091080Z","iopub.execute_input":"2025-05-25T17:22:27.091328Z","iopub.status.idle":"2025-05-25T17:22:27.123797Z","shell.execute_reply.started":"2025-05-25T17:22:27.091300Z","shell.execute_reply":"2025-05-25T17:22:27.123272Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# 10. Fit One-Class SVM on soil-only training data\nsvm = OneClassSVM(kernel='rbf', gamma='scale', nu=0.1)  # nu ≈ expected fraction of outliers\nsvm.fit(train_features)\n\n# Predict on test set\n# Output: 1 = inlier (soil), -1 = outlier (non-soil)\nsvm_preds = svm.predict(test_features)\nbinary_preds = [1 if p == 1 else 0 for p in svm_preds]  # Convert to 1/0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T17:22:27.124443Z","iopub.execute_input":"2025-05-25T17:22:27.124707Z","iopub.status.idle":"2025-05-25T17:22:27.260702Z","shell.execute_reply.started":"2025-05-25T17:22:27.124689Z","shell.execute_reply":"2025-05-25T17:22:27.260199Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# 11. Save Submission\nsubmission = pd.DataFrame({\n    'image_id': test_ids,\n    'label': binary_preds\n})\nsubmission.to_csv('submission.csv', index=False)\nprint(\" Submission file saved as 'submission.csv'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T17:22:27.261304Z","iopub.execute_input":"2025-05-25T17:22:27.261489Z","iopub.status.idle":"2025-05-25T17:22:27.273929Z","shell.execute_reply.started":"2025-05-25T17:22:27.261475Z","shell.execute_reply":"2025-05-25T17:22:27.273313Z"}},"outputs":[{"name":"stdout","text":" Submission file saved as 'submission.csv'\n","output_type":"stream"}],"execution_count":29}]}
